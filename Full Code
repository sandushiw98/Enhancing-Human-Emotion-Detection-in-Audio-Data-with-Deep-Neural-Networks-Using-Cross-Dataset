#Mounting the Resource location through Google Drive
from google.colab import drive
import os

drive.mount('/content/drive')

# Combine both REVDASS and TESS Dataset and Augmentation

!pip install joblib

import os
import shutil
import random
import time
import joblib
import librosa
import numpy as np
import resampy
from pathlib import Path
import matplotlib.pyplot as plt
import tensorflow as tf
from keras.layers import Dense, Conv1D, Flatten, Dropout, Activation, BatchNormalization, MaxPooling1D, Add, Input, GlobalAveragePooling1D
from keras.models import Model
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Configuration paths
TRAINING_FILES_PATH = '/content/drive/MyDrive/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/features'
TESS_ORIGINAL_FOLDER_PATH = '/content/drive/MyDrive/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/TESS_Toronto_emotional_speech_set_data'

class TESSPipeline:

    @staticmethod
    def create_tess_folders(path):
        """
        Create and fill folders Actor_25 if YAF and Actor_26 if OAF.
        Files will be copied and renamed, not moved, to avoid messing up
        during the development of the pipeline.
        Actor_25 and Actor_26 folders must be created before running this script.
        Example filename: 03-01-07-02-02-01-01.wav
        """
        label_conversion = {
            '01': 'neutral',
            '03': 'happy',
            '04': 'sad',
            '05': 'angry',
            '06': 'fear',
            '07': 'disgust',
            '08': 'ps'  # pleasant surprise
        }

        for subdir, _, files in os.walk(path):
            for filename in files:
                try:
                    if filename.startswith('OAF'):
                        destination_path = os.path.join(TRAINING_FILES_PATH, 'Actor_26')
                    else:
                        destination_path = os.path.join(TRAINING_FILES_PATH, 'Actor_25')

                    old_file_path = os.path.join(subdir, filename)
                    base, extension = os.path.splitext(filename)

                    for key, value in label_conversion.items():
                        if base.endswith(value):
                            random_list = random.sample(range(10, 99), 7)
                            file_name = '-'.join(map(str, random_list))
                            file_name_with_correct_emotion = file_name[:6] + key + file_name[8:] + extension
                            new_file_path = os.path.join(destination_path, file_name_with_correct_emotion)

                            # Ensure destination directory exists
                            os.makedirs(destination_path, exist_ok=True)
                            shutil.copy(old_file_path, new_file_path)
                            break  # Move to the next file after finding the correct emotion
                except Exception as e:
                    print(f"Error processing file {filename}: {e}")

    @staticmethod
    def create_calm_folders(path):

        actor_27_path = os.path.join(TRAINING_FILES_PATH, 'Actor_27')
        os.makedirs(actor_27_path, exist_ok=True)

        for subdir, dirs, files in os.walk(path):
            for filename in files:
                parts = filename.split('-')  # Split the filename into parts
                if len(parts) >= 3 and parts[2] == '02':  # Check if the third part is '02'
                    full_file_path = os.path.join(subdir, filename)  # Construct the full file path

                    # First copy with the original filename
                    destination_file_path_1 = os.path.join(actor_27_path, filename)

                    # Ensure source and destination are not the same
                    if full_file_path != destination_file_path_1:
                        shutil.copy(full_file_path, destination_file_path_1)

                    # Modify the first number from '03' to '04' for the second copy
                    parts[0] = '04'
                    modified_filename = '-'.join(parts)
                    destination_file_path_2 = os.path.join(actor_27_path, modified_filename)

                    # Ensure source and destination are not the same
                    if full_file_path != destination_file_path_2:
                        shutil.copy(full_file_path, destination_file_path_2)

if __name__ == '__main__':
    TESSPipeline.create_tess_folders(TESS_ORIGINAL_FOLDER_PATH)
    TESSPipeline.create_calm_folders(TRAINING_FILES_PATH)

#Extract feature from audio file using MFCC

!pip install joblib librosa resampy

# Configuration paths
SAVE_DIR_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/joblib_features'
TRAINING_FILES_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/features'

class CreateFeatures:

    @staticmethod
    def features_creator(path, save_dir) -> str:
        """
        This function creates the dataset and saves both data and labels in
        two files, X.joblib and y.joblib in the joblib_features folder.
        With this method, you can persist your features and train quickly
        new machine learning models instead of reloading the features
        every time with this pipeline.
        """

        lst = []

        start_time = time.time()

        for subdir, dirs, files in os.walk(path):
            for file in files:
                try:
                    # Load librosa array, obtain mfcss, store the file and the mcss information in a new array
                    X, sample_rate = librosa.load(os.path.join(subdir, file), res_type='kaiser_fast')
                    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)
                    # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7
                    # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.
                    file_label = int(file[7:8]) - 1
                    arr = mfccs, file_label
                    lst.append(arr)
                # If the file is not valid, skip it
                except ValueError as err:
                    print(err)
                    continue

        print("--- Data loaded. Loading time: %s seconds ---" % (time.time() - start_time))

        # Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.
        X, y = zip(*lst)

        # Array conversion
        X, y = np.asarray(X), np.asarray(y)

        # Array shape check
        print(X.shape, y.shape)

        # Preparing features dump
        X_name, y_name = 'X.joblib', 'y.joblib'

        joblib.dump(X, os.path.join(save_dir, X_name))
        joblib.dump(y, os.path.join(save_dir, y_name))

        return "Completed"

if __name__ == '__main__':
    print('Routine started')
    FEATURES = CreateFeatures.features_creator(path=TRAINING_FILES_PATH, save_dir=SAVE_DIR_PATH)
    print('Routine completed.')

# Configuration paths
SAVE_DIR_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/joblib_features'
MODEL_DIR_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/model'

# Set up GPU memory growth
physical_devices = tf.config.experimental.list_physical_devices('GPU')
if physical_devices:
    for device in physical_devices:
        tf.config.experimental.set_memory_growth(device, True)

class TrainModel:

    @staticmethod
    def residual_block(x, filters, kernel_size=3, stride=1):
        res = Conv1D(filters, kernel_size, padding='same', strides=stride, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
        res = BatchNormalization()(res)
        res = Activation('relu')(res)
        res = Conv1D(filters, kernel_size, padding='same', strides=stride, kernel_regularizer=tf.keras.regularizers.l2(0.001))(res)
        res = BatchNormalization()(res)

        if x.shape[-1] != filters:
            x = Conv1D(filters, kernel_size, padding='same', strides=stride, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
            x = BatchNormalization()(x)

        x = Add()([x, res])
        x = Activation('relu')(x)
        return x
