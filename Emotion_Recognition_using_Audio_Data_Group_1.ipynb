{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandushiw98/Enhancing-Human-Emotion-Detection-in-Audio-Data-with-Deep-Neural-Networks-Using-Cross-Dataset/blob/main/Emotion_Recognition_using_Audio_Data_Group_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting the Resource location through Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "sUH0AF3lYFhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31880206-d4db-46c3-ebb4-201399e2028f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both REVDASS and TESS Dataset and Augmentation\n",
        "\n",
        "!pip install joblib\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Configuration paths\n",
        "TRAINING_FILES_PATH = '/content/drive/MyDrive/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/features'\n",
        "TESS_ORIGINAL_FOLDER_PATH = '/content/drive/MyDrive/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/TESS_Toronto_emotional_speech_set_data'\n",
        "\n",
        "class TESSPipeline:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_tess_folders(path):\n",
        "        \"\"\"\n",
        "        Create and fill folders Actor_25 if YAF and Actor_26 if OAF.\n",
        "        Files will be copied and renamed, not moved, to avoid messing up\n",
        "        during the development of the pipeline.\n",
        "        Actor_25 and Actor_26 folders must be created before running this script.\n",
        "        Example filename: 03-01-07-02-02-01-01.wav\n",
        "        \"\"\"\n",
        "        label_conversion = {\n",
        "            '01': 'neutral',\n",
        "            '03': 'happy',\n",
        "            '04': 'sad',\n",
        "            '05': 'angry',\n",
        "            '06': 'fear',\n",
        "            '07': 'disgust',\n",
        "            '08': 'ps'  # pleasant surprise\n",
        "        }\n",
        "\n",
        "        for subdir, _, files in os.walk(path):\n",
        "            for filename in files:\n",
        "                try:\n",
        "                    if filename.startswith('OAF'):\n",
        "                        destination_path = os.path.join(TRAINING_FILES_PATH, 'Actor_26')\n",
        "                    else:\n",
        "                        destination_path = os.path.join(TRAINING_FILES_PATH, 'Actor_25')\n",
        "\n",
        "                    old_file_path = os.path.join(subdir, filename)\n",
        "                    base, extension = os.path.splitext(filename)\n",
        "\n",
        "                    for key, value in label_conversion.items():\n",
        "                        if base.endswith(value):\n",
        "                            random_list = random.sample(range(10, 99), 7)\n",
        "                            file_name = '-'.join(map(str, random_list))\n",
        "                            file_name_with_correct_emotion = file_name[:6] + key + file_name[8:] + extension\n",
        "                            new_file_path = os.path.join(destination_path, file_name_with_correct_emotion)\n",
        "\n",
        "                            # Ensure destination directory exists\n",
        "                            os.makedirs(destination_path, exist_ok=True)\n",
        "                            shutil.copy(old_file_path, new_file_path)\n",
        "                            break  # Move to the next file after finding the correct emotion\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing file {filename}: {e}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def create_calm_folders(path):\n",
        "\n",
        "        actor_27_path = os.path.join(TRAINING_FILES_PATH, 'Actor_27')\n",
        "        os.makedirs(actor_27_path, exist_ok=True)\n",
        "\n",
        "        for subdir, dirs, files in os.walk(path):\n",
        "            for filename in files:\n",
        "                parts = filename.split('-')  # Split the filename into parts\n",
        "                if len(parts) >= 3 and parts[2] == '02':  # Check if the third part is '02'\n",
        "                    full_file_path = os.path.join(subdir, filename)  # Construct the full file path\n",
        "\n",
        "                    # First copy with the original filename\n",
        "                    destination_file_path_1 = os.path.join(actor_27_path, filename)\n",
        "\n",
        "                    # Ensure source and destination are not the same\n",
        "                    if full_file_path != destination_file_path_1:\n",
        "                        shutil.copy(full_file_path, destination_file_path_1)\n",
        "\n",
        "                    # Modify the first number from '03' to '04' for the second copy\n",
        "                    parts[0] = '04'\n",
        "                    modified_filename = '-'.join(parts)\n",
        "                    destination_file_path_2 = os.path.join(actor_27_path, modified_filename)\n",
        "\n",
        "                    # Ensure source and destination are not the same\n",
        "                    if full_file_path != destination_file_path_2:\n",
        "                        shutil.copy(full_file_path, destination_file_path_2)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    TESSPipeline.create_tess_folders(TESS_ORIGINAL_FOLDER_PATH)\n",
        "    TESSPipeline.create_calm_folders(TRAINING_FILES_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4YPzcWtY_im",
        "outputId": "93fa63d8-df99-487a-c0a4-b11ad8afd968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NWFoKC48X-3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TlHQE3SXwII",
        "outputId": "df2929c0-9f55-4f52-bd33-ac3d70f384f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Routine started\n",
            "--- Data loaded. Loading time: 733.5363960266113 seconds ---\n",
            "(8804, 40) (8804,)\n",
            "Routine completed.\n"
          ]
        }
      ],
      "source": [
        "#Extract feature from audio file using MFCC\n",
        "\n",
        "!pip install joblib librosa resampy\n",
        "\n",
        "import os\n",
        "import time\n",
        "import joblib\n",
        "import librosa\n",
        "import numpy as np\n",
        "import resampy\n",
        "\n",
        "# Configuration paths\n",
        "SAVE_DIR_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/joblib_features'\n",
        "TRAINING_FILES_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/features'\n",
        "\n",
        "class CreateFeatures:\n",
        "\n",
        "    @staticmethod\n",
        "    def features_creator(path, save_dir) -> str:\n",
        "        \"\"\"\n",
        "        This function creates the dataset and saves both data and labels in\n",
        "        two files, X.joblib and y.joblib in the joblib_features folder.\n",
        "        With this method, you can persist your features and train quickly\n",
        "        new machine learning models instead of reloading the features\n",
        "        every time with this pipeline.\n",
        "        \"\"\"\n",
        "\n",
        "        lst = []\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for subdir, dirs, files in os.walk(path):\n",
        "            for file in files:\n",
        "                try:\n",
        "                    # Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "                    X, sample_rate = librosa.load(os.path.join(subdir, file), res_type='kaiser_fast')\n",
        "                    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "                    # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "                    # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "                    file_label = int(file[7:8]) - 1\n",
        "                    arr = mfccs, file_label\n",
        "                    lst.append(arr)\n",
        "                # If the file is not valid, skip it\n",
        "                except ValueError as err:\n",
        "                    print(err)\n",
        "                    continue\n",
        "\n",
        "        print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "        # Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "        X, y = zip(*lst)\n",
        "\n",
        "        # Array conversion\n",
        "        X, y = np.asarray(X), np.asarray(y)\n",
        "\n",
        "        # Array shape check\n",
        "        print(X.shape, y.shape)\n",
        "\n",
        "        # Preparing features dump\n",
        "        X_name, y_name = 'X.joblib', 'y.joblib'\n",
        "\n",
        "        joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "        joblib.dump(y, os.path.join(save_dir, y_name))\n",
        "\n",
        "        return \"Completed\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('Routine started')\n",
        "    FEATURES = CreateFeatures.features_creator(path=TRAINING_FILES_PATH, save_dir=SAVE_DIR_PATH)\n",
        "    print('Routine completed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Model using Neural Network and Testing\n",
        "\n",
        "!pip install joblib librosa resampy tensorflow keras\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Conv1D, Flatten, Dropout, Activation, BatchNormalization, MaxPooling1D, Add, Input, GlobalAveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Configuration paths\n",
        "SAVE_DIR_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/joblib_features'\n",
        "MODEL_DIR_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/model'\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up GPU memory growth\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "class TrainModel:\n",
        "\n",
        "    @staticmethod\n",
        "    def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "        res = Conv1D(filters, kernel_size, padding='same', strides=stride, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "        res = BatchNormalization()(res)\n",
        "        res = Activation('relu')(res)\n",
        "        res = Conv1D(filters, kernel_size, padding='same', strides=stride, kernel_regularizer=tf.keras.regularizers.l2(0.001))(res)\n",
        "        res = BatchNormalization()(res)\n",
        "\n",
        "        if x.shape[-1] != filters:\n",
        "            x = Conv1D(filters, kernel_size, padding='same', strides=stride, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "\n",
        "        x = Add()([x, res])\n",
        "        x = Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def train_neural_network(X, y) -> None:\n",
        "        \"\"\"\n",
        "        This function trains the neural network.\n",
        "        \"\"\"\n",
        "\n",
        "        # Normalize the data\n",
        "        scaler = StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "        x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "        x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "        print(x_traincnn.shape, x_testcnn.shape)\n",
        "\n",
        "        input_shape = (40, 1)\n",
        "        inputs = Input(shape=input_shape)\n",
        "\n",
        "        x = Conv1D(64, 3, padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = MaxPooling1D(pool_size=2)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        x = TrainModel.residual_block(x, 128)\n",
        "        x = MaxPooling1D(pool_size=2)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        x = TrainModel.residual_block(x, 256)\n",
        "        x = MaxPooling1D(pool_size=2)(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "\n",
        "        x = TrainModel.residual_block(x, 512)\n",
        "        x = MaxPooling1D(pool_size=2)(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "\n",
        "        x = GlobalAveragePooling1D()(x)\n",
        "        x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        outputs = Dense(8, activation='softmax')(x)\n",
        "\n",
        "        model = Model(inputs, outputs)\n",
        "\n",
        "        print(model.summary())\n",
        "\n",
        "        model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "        # Early stopping and learning rate reduction\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "        cnn_history = model.fit(x_traincnn, y_train, batch_size=64, epochs=300, validation_data=(x_testcnn, y_test), callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "        # Loss plotting\n",
        "        plt.plot(cnn_history.history['loss'])\n",
        "        plt.plot(cnn_history.history['val_loss'])\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.savefig('loss.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Accuracy plotting\n",
        "        plt.plot(cnn_history.history['accuracy'])\n",
        "        plt.plot(cnn_history.history['val_accuracy'])\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.savefig('accuracy.png')\n",
        "\n",
        "        predictions = np.argmax(model.predict(x_testcnn), axis=1)\n",
        "        new_y_test = y_test.astype(int)\n",
        "        matrix = confusion_matrix(new_y_test, predictions)\n",
        "\n",
        "        print(classification_report(new_y_test, predictions))\n",
        "        print(matrix)\n",
        "\n",
        "        model_name = 'Emotion_Voice_Detection_Model.h5'\n",
        "\n",
        "        # Save model and weights\n",
        "        model_path = Path(MODEL_DIR_PATH) / model_name\n",
        "        model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        model.save(model_path)\n",
        "        print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('Training started')\n",
        "    X = joblib.load(Path(SAVE_DIR_PATH) / 'X.joblib')\n",
        "    y = joblib.load(Path(SAVE_DIR_PATH) / 'y.joblib')\n",
        "    NEURAL_NET = TrainModel.train_neural_network(X=X, y=y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uu9xqV4Ueb3l",
        "outputId": "2f40bd97-cc11-43e0-ce03-2375176ee6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training started\n",
            "(5898, 40, 1) (2906, 40, 1)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 40, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 40, 64)               256       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 40, 64)               256       ['conv1d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 40, 64)               0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 20, 64)               0         ['activation[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 20, 64)               0         ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 20, 128)              24704     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 20, 128)              512       ['conv1d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 20, 128)              0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 20, 128)              24704     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 20, 128)              49280     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 20, 128)              512       ['conv1d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 20, 128)              512       ['conv1d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 20, 128)              0         ['batch_normalization_3[0][0]'\n",
            "                                                                    , 'batch_normalization_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 20, 128)              0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPoolin  (None, 10, 128)              0         ['activation_2[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 10, 128)              0         ['max_pooling1d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 10, 256)              98560     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 10, 256)              1024      ['conv1d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 10, 256)              0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 10, 256)              98560     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 10, 256)              196864    ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 10, 256)              1024      ['conv1d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 10, 256)              1024      ['conv1d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 10, 256)              0         ['batch_normalization_6[0][0]'\n",
            "                                                                    , 'batch_normalization_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 10, 256)              0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPoolin  (None, 5, 256)               0         ['activation_4[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 5, 256)               0         ['max_pooling1d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 5, 512)               393728    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 5, 512)               2048      ['conv1d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 5, 512)               0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)           (None, 5, 512)               393728    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)           (None, 5, 512)               786944    ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 5, 512)               2048      ['conv1d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 5, 512)               2048      ['conv1d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 5, 512)               0         ['batch_normalization_9[0][0]'\n",
            "                                                                    , 'batch_normalization_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 5, 512)               0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPoolin  (None, 2, 512)               0         ['activation_6[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 2, 512)               0         ['max_pooling1d_3[0][0]']     \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 512)                  0         ['dropout_3[0][0]']           \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 512)                  262656    ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 256)                  131328    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 256)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 8)                    2056      ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2474376 (9.44 MB)\n",
            "Trainable params: 2468872 (9.42 MB)\n",
            "Non-trainable params: 5504 (21.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/300\n",
            "93/93 [==============================] - 18s 34ms/step - loss: 5.6781 - accuracy: 0.1653 - val_loss: 5.0654 - val_accuracy: 0.1101 - lr: 1.0000e-04\n",
            "Epoch 2/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 5.0839 - accuracy: 0.2080 - val_loss: 5.1780 - val_accuracy: 0.1101 - lr: 1.0000e-04\n",
            "Epoch 3/300\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 4.9030 - accuracy: 0.2399 - val_loss: 5.1750 - val_accuracy: 0.1122 - lr: 1.0000e-04\n",
            "Epoch 4/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 4.7469 - accuracy: 0.3050 - val_loss: 5.0706 - val_accuracy: 0.2006 - lr: 1.0000e-04\n",
            "Epoch 5/300\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 4.6173 - accuracy: 0.3438 - val_loss: 4.8494 - val_accuracy: 0.3032 - lr: 1.0000e-04\n",
            "Epoch 6/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 4.5090 - accuracy: 0.3850 - val_loss: 4.6658 - val_accuracy: 0.3369 - lr: 1.0000e-04\n",
            "Epoch 7/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 4.3951 - accuracy: 0.4234 - val_loss: 4.5171 - val_accuracy: 0.3816 - lr: 1.0000e-04\n",
            "Epoch 8/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 4.2828 - accuracy: 0.4615 - val_loss: 4.2856 - val_accuracy: 0.4580 - lr: 1.0000e-04\n",
            "Epoch 9/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 4.1921 - accuracy: 0.4917 - val_loss: 4.1823 - val_accuracy: 0.4952 - lr: 1.0000e-04\n",
            "Epoch 10/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 4.0891 - accuracy: 0.5415 - val_loss: 4.0631 - val_accuracy: 0.5465 - lr: 1.0000e-04\n",
            "Epoch 11/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 3.9883 - accuracy: 0.5665 - val_loss: 3.9473 - val_accuracy: 0.5816 - lr: 1.0000e-04\n",
            "Epoch 12/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 3.9103 - accuracy: 0.5933 - val_loss: 3.8484 - val_accuracy: 0.6074 - lr: 1.0000e-04\n",
            "Epoch 13/300\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 3.8336 - accuracy: 0.6090 - val_loss: 3.7750 - val_accuracy: 0.6301 - lr: 1.0000e-04\n",
            "Epoch 14/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 3.7617 - accuracy: 0.6267 - val_loss: 3.7025 - val_accuracy: 0.6507 - lr: 1.0000e-04\n",
            "Epoch 15/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 3.6787 - accuracy: 0.6573 - val_loss: 3.6174 - val_accuracy: 0.6717 - lr: 1.0000e-04\n",
            "Epoch 16/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 3.6320 - accuracy: 0.6606 - val_loss: 3.5453 - val_accuracy: 0.6920 - lr: 1.0000e-04\n",
            "Epoch 17/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 3.5625 - accuracy: 0.6841 - val_loss: 3.4810 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
            "Epoch 18/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 3.5244 - accuracy: 0.6890 - val_loss: 3.4525 - val_accuracy: 0.7127 - lr: 1.0000e-04\n",
            "Epoch 19/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 3.4776 - accuracy: 0.6936 - val_loss: 3.3644 - val_accuracy: 0.7261 - lr: 1.0000e-04\n",
            "Epoch 20/300\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 3.4197 - accuracy: 0.7072 - val_loss: 3.3226 - val_accuracy: 0.7347 - lr: 1.0000e-04\n",
            "Epoch 21/300\n",
            "93/93 [==============================] - 3s 38ms/step - loss: 3.3580 - accuracy: 0.7177 - val_loss: 3.2654 - val_accuracy: 0.7443 - lr: 1.0000e-04\n",
            "Epoch 22/300\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 3.3104 - accuracy: 0.7255 - val_loss: 3.2494 - val_accuracy: 0.7433 - lr: 1.0000e-04\n",
            "Epoch 23/300\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 3.2671 - accuracy: 0.7325 - val_loss: 3.1602 - val_accuracy: 0.7681 - lr: 1.0000e-04\n",
            "Epoch 24/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 3.2171 - accuracy: 0.7408 - val_loss: 3.1069 - val_accuracy: 0.7749 - lr: 1.0000e-04\n",
            "Epoch 25/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 3.1645 - accuracy: 0.7492 - val_loss: 3.0732 - val_accuracy: 0.7770 - lr: 1.0000e-04\n",
            "Epoch 26/300\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 3.1187 - accuracy: 0.7506 - val_loss: 3.0168 - val_accuracy: 0.7860 - lr: 1.0000e-04\n",
            "Epoch 27/300\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 3.0657 - accuracy: 0.7599 - val_loss: 2.9828 - val_accuracy: 0.7894 - lr: 1.0000e-04\n",
            "Epoch 28/300\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 3.0096 - accuracy: 0.7679 - val_loss: 2.9259 - val_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 29/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 2.9842 - accuracy: 0.7675 - val_loss: 2.8864 - val_accuracy: 0.8014 - lr: 1.0000e-04\n",
            "Epoch 30/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.9347 - accuracy: 0.7765 - val_loss: 2.8364 - val_accuracy: 0.8039 - lr: 1.0000e-04\n",
            "Epoch 31/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 2.9049 - accuracy: 0.7740 - val_loss: 2.8011 - val_accuracy: 0.8066 - lr: 1.0000e-04\n",
            "Epoch 32/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 2.8609 - accuracy: 0.7823 - val_loss: 2.7641 - val_accuracy: 0.8076 - lr: 1.0000e-04\n",
            "Epoch 33/300\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 2.8198 - accuracy: 0.7921 - val_loss: 2.7128 - val_accuracy: 0.8156 - lr: 1.0000e-04\n",
            "Epoch 34/300\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 2.7873 - accuracy: 0.7842 - val_loss: 2.6774 - val_accuracy: 0.8156 - lr: 1.0000e-04\n",
            "Epoch 35/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 2.7449 - accuracy: 0.7891 - val_loss: 2.6351 - val_accuracy: 0.8224 - lr: 1.0000e-04\n",
            "Epoch 36/300\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 2.7032 - accuracy: 0.7921 - val_loss: 2.5988 - val_accuracy: 0.8269 - lr: 1.0000e-04\n",
            "Epoch 37/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.6740 - accuracy: 0.7965 - val_loss: 2.5663 - val_accuracy: 0.8273 - lr: 1.0000e-04\n",
            "Epoch 38/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.6164 - accuracy: 0.8042 - val_loss: 2.5292 - val_accuracy: 0.8228 - lr: 1.0000e-04\n",
            "Epoch 39/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.5830 - accuracy: 0.8098 - val_loss: 2.4993 - val_accuracy: 0.8259 - lr: 1.0000e-04\n",
            "Epoch 40/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.5416 - accuracy: 0.8120 - val_loss: 2.4570 - val_accuracy: 0.8262 - lr: 1.0000e-04\n",
            "Epoch 41/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.5125 - accuracy: 0.8115 - val_loss: 2.4100 - val_accuracy: 0.8410 - lr: 1.0000e-04\n",
            "Epoch 42/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 2.4712 - accuracy: 0.8126 - val_loss: 2.3630 - val_accuracy: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 43/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 2.4433 - accuracy: 0.8128 - val_loss: 2.3394 - val_accuracy: 0.8414 - lr: 1.0000e-04\n",
            "Epoch 44/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 2.4074 - accuracy: 0.8169 - val_loss: 2.3110 - val_accuracy: 0.8424 - lr: 1.0000e-04\n",
            "Epoch 45/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 2.3810 - accuracy: 0.8164 - val_loss: 2.2784 - val_accuracy: 0.8496 - lr: 1.0000e-04\n",
            "Epoch 46/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.3286 - accuracy: 0.8269 - val_loss: 2.2372 - val_accuracy: 0.8462 - lr: 1.0000e-04\n",
            "Epoch 47/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 2.2846 - accuracy: 0.8245 - val_loss: 2.2088 - val_accuracy: 0.8472 - lr: 1.0000e-04\n",
            "Epoch 48/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 2.2563 - accuracy: 0.8281 - val_loss: 2.1802 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 49/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 2.2263 - accuracy: 0.8311 - val_loss: 2.1586 - val_accuracy: 0.8507 - lr: 1.0000e-04\n",
            "Epoch 50/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 2.1921 - accuracy: 0.8344 - val_loss: 2.1082 - val_accuracy: 0.8575 - lr: 1.0000e-04\n",
            "Epoch 51/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 2.1596 - accuracy: 0.8364 - val_loss: 2.0879 - val_accuracy: 0.8558 - lr: 1.0000e-04\n",
            "Epoch 52/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 2.1285 - accuracy: 0.8401 - val_loss: 2.0527 - val_accuracy: 0.8579 - lr: 1.0000e-04\n",
            "Epoch 53/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.0947 - accuracy: 0.8383 - val_loss: 2.0440 - val_accuracy: 0.8451 - lr: 1.0000e-04\n",
            "Epoch 54/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.0694 - accuracy: 0.8391 - val_loss: 1.9952 - val_accuracy: 0.8630 - lr: 1.0000e-04\n",
            "Epoch 55/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.0280 - accuracy: 0.8450 - val_loss: 1.9673 - val_accuracy: 0.8596 - lr: 1.0000e-04\n",
            "Epoch 56/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 2.0021 - accuracy: 0.8454 - val_loss: 1.9343 - val_accuracy: 0.8630 - lr: 1.0000e-04\n",
            "Epoch 57/300\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 1.9821 - accuracy: 0.8411 - val_loss: 1.9093 - val_accuracy: 0.8641 - lr: 1.0000e-04\n",
            "Epoch 58/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 1.9367 - accuracy: 0.8549 - val_loss: 1.8699 - val_accuracy: 0.8668 - lr: 1.0000e-04\n",
            "Epoch 59/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 1.9121 - accuracy: 0.8505 - val_loss: 1.8448 - val_accuracy: 0.8679 - lr: 1.0000e-04\n",
            "Epoch 60/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.8733 - accuracy: 0.8537 - val_loss: 1.8263 - val_accuracy: 0.8672 - lr: 1.0000e-04\n",
            "Epoch 61/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.8551 - accuracy: 0.8566 - val_loss: 1.7819 - val_accuracy: 0.8730 - lr: 1.0000e-04\n",
            "Epoch 62/300\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 1.8316 - accuracy: 0.8523 - val_loss: 1.7678 - val_accuracy: 0.8741 - lr: 1.0000e-04\n",
            "Epoch 63/300\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 1.7984 - accuracy: 0.8606 - val_loss: 1.7422 - val_accuracy: 0.8723 - lr: 1.0000e-04\n",
            "Epoch 64/300\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 1.7708 - accuracy: 0.8625 - val_loss: 1.7199 - val_accuracy: 0.8723 - lr: 1.0000e-04\n",
            "Epoch 65/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 1.7488 - accuracy: 0.8576 - val_loss: 1.6922 - val_accuracy: 0.8741 - lr: 1.0000e-04\n",
            "Epoch 66/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 1.7279 - accuracy: 0.8577 - val_loss: 1.6578 - val_accuracy: 0.8789 - lr: 1.0000e-04\n",
            "Epoch 67/300\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 1.6991 - accuracy: 0.8622 - val_loss: 1.6492 - val_accuracy: 0.8768 - lr: 1.0000e-04\n",
            "Epoch 68/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 1.6787 - accuracy: 0.8610 - val_loss: 1.6106 - val_accuracy: 0.8820 - lr: 1.0000e-04\n",
            "Epoch 69/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.6514 - accuracy: 0.8671 - val_loss: 1.6068 - val_accuracy: 0.8789 - lr: 1.0000e-04\n",
            "Epoch 70/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 1.6142 - accuracy: 0.8723 - val_loss: 1.5706 - val_accuracy: 0.8754 - lr: 1.0000e-04\n",
            "Epoch 71/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 1.5860 - accuracy: 0.8703 - val_loss: 1.5438 - val_accuracy: 0.8809 - lr: 1.0000e-04\n",
            "Epoch 72/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 1.5770 - accuracy: 0.8674 - val_loss: 1.5213 - val_accuracy: 0.8830 - lr: 1.0000e-04\n",
            "Epoch 73/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.5642 - accuracy: 0.8710 - val_loss: 1.5057 - val_accuracy: 0.8799 - lr: 1.0000e-04\n",
            "Epoch 74/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.5239 - accuracy: 0.8779 - val_loss: 1.4953 - val_accuracy: 0.8796 - lr: 1.0000e-04\n",
            "Epoch 75/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 1.5004 - accuracy: 0.8805 - val_loss: 1.4603 - val_accuracy: 0.8861 - lr: 1.0000e-04\n",
            "Epoch 76/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.4945 - accuracy: 0.8708 - val_loss: 1.4482 - val_accuracy: 0.8851 - lr: 1.0000e-04\n",
            "Epoch 77/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.4703 - accuracy: 0.8786 - val_loss: 1.4254 - val_accuracy: 0.8861 - lr: 1.0000e-04\n",
            "Epoch 78/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 1.4529 - accuracy: 0.8823 - val_loss: 1.4097 - val_accuracy: 0.8854 - lr: 1.0000e-04\n",
            "Epoch 79/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 1.4315 - accuracy: 0.8781 - val_loss: 1.3851 - val_accuracy: 0.8885 - lr: 1.0000e-04\n",
            "Epoch 80/300\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 1.4168 - accuracy: 0.8793 - val_loss: 1.3645 - val_accuracy: 0.8885 - lr: 1.0000e-04\n",
            "Epoch 81/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.3906 - accuracy: 0.8817 - val_loss: 1.3578 - val_accuracy: 0.8868 - lr: 1.0000e-04\n",
            "Epoch 82/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 1.3636 - accuracy: 0.8872 - val_loss: 1.3374 - val_accuracy: 0.8875 - lr: 1.0000e-04\n",
            "Epoch 83/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 1.3413 - accuracy: 0.8927 - val_loss: 1.3324 - val_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 84/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 1.3327 - accuracy: 0.8883 - val_loss: 1.3107 - val_accuracy: 0.8813 - lr: 1.0000e-04\n",
            "Epoch 85/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 1.3208 - accuracy: 0.8823 - val_loss: 1.2874 - val_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 86/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 1.2816 - accuracy: 0.8947 - val_loss: 1.2708 - val_accuracy: 0.8882 - lr: 1.0000e-04\n",
            "Epoch 87/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 1.2722 - accuracy: 0.8905 - val_loss: 1.2523 - val_accuracy: 0.8902 - lr: 1.0000e-04\n",
            "Epoch 88/300\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 1.2686 - accuracy: 0.8861 - val_loss: 1.2348 - val_accuracy: 0.8906 - lr: 1.0000e-04\n",
            "Epoch 89/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 1.2393 - accuracy: 0.8906 - val_loss: 1.2362 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
            "Epoch 90/300\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 1.2206 - accuracy: 0.8930 - val_loss: 1.2097 - val_accuracy: 0.8864 - lr: 1.0000e-04\n",
            "Epoch 91/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 1.2079 - accuracy: 0.8949 - val_loss: 1.2127 - val_accuracy: 0.8861 - lr: 1.0000e-04\n",
            "Epoch 92/300\n",
            "93/93 [==============================] - 5s 54ms/step - loss: 1.2084 - accuracy: 0.8923 - val_loss: 1.1692 - val_accuracy: 0.8964 - lr: 1.0000e-04\n",
            "Epoch 93/300\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 1.1822 - accuracy: 0.8962 - val_loss: 1.1691 - val_accuracy: 0.8940 - lr: 1.0000e-04\n",
            "Epoch 94/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 1.1659 - accuracy: 0.8971 - val_loss: 1.1545 - val_accuracy: 0.8930 - lr: 1.0000e-04\n",
            "Epoch 95/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 1.1589 - accuracy: 0.8935 - val_loss: 1.1320 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
            "Epoch 96/300\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 1.1494 - accuracy: 0.8910 - val_loss: 1.1239 - val_accuracy: 0.8971 - lr: 1.0000e-04\n",
            "Epoch 97/300\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 1.1182 - accuracy: 0.8996 - val_loss: 1.1114 - val_accuracy: 0.8975 - lr: 1.0000e-04\n",
            "Epoch 98/300\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 1.1115 - accuracy: 0.9010 - val_loss: 1.1053 - val_accuracy: 0.8913 - lr: 1.0000e-04\n",
            "Epoch 99/300\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 1.0920 - accuracy: 0.9022 - val_loss: 1.0949 - val_accuracy: 0.8988 - lr: 1.0000e-04\n",
            "Epoch 100/300\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 1.0816 - accuracy: 0.9040 - val_loss: 1.0795 - val_accuracy: 0.8940 - lr: 1.0000e-04\n",
            "Epoch 101/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 1.0668 - accuracy: 0.9061 - val_loss: 1.0622 - val_accuracy: 0.9006 - lr: 1.0000e-04\n",
            "Epoch 102/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 1.0539 - accuracy: 0.9025 - val_loss: 1.0590 - val_accuracy: 0.8988 - lr: 1.0000e-04\n",
            "Epoch 103/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 1.0405 - accuracy: 0.9098 - val_loss: 1.0358 - val_accuracy: 0.9016 - lr: 1.0000e-04\n",
            "Epoch 104/300\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 1.0266 - accuracy: 0.9095 - val_loss: 1.0443 - val_accuracy: 0.8947 - lr: 1.0000e-04\n",
            "Epoch 105/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 1.0165 - accuracy: 0.9069 - val_loss: 1.0139 - val_accuracy: 0.9043 - lr: 1.0000e-04\n",
            "Epoch 106/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 1.0102 - accuracy: 0.9083 - val_loss: 1.0183 - val_accuracy: 0.9009 - lr: 1.0000e-04\n",
            "Epoch 107/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 1.0098 - accuracy: 0.9062 - val_loss: 0.9959 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
            "Epoch 108/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.9848 - accuracy: 0.9145 - val_loss: 0.9903 - val_accuracy: 0.9019 - lr: 1.0000e-04\n",
            "Epoch 109/300\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.9649 - accuracy: 0.9113 - val_loss: 0.9810 - val_accuracy: 0.9040 - lr: 1.0000e-04\n",
            "Epoch 110/300\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.9678 - accuracy: 0.9096 - val_loss: 0.9795 - val_accuracy: 0.9036 - lr: 1.0000e-04\n",
            "Epoch 111/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.9494 - accuracy: 0.9110 - val_loss: 0.9564 - val_accuracy: 0.9074 - lr: 1.0000e-04\n",
            "Epoch 112/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.9296 - accuracy: 0.9173 - val_loss: 0.9515 - val_accuracy: 0.9019 - lr: 1.0000e-04\n",
            "Epoch 113/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.9224 - accuracy: 0.9168 - val_loss: 0.9523 - val_accuracy: 0.9030 - lr: 1.0000e-04\n",
            "Epoch 114/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.9294 - accuracy: 0.9135 - val_loss: 0.9314 - val_accuracy: 0.9074 - lr: 1.0000e-04\n",
            "Epoch 115/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.9148 - accuracy: 0.9152 - val_loss: 0.9225 - val_accuracy: 0.9023 - lr: 1.0000e-04\n",
            "Epoch 116/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.8963 - accuracy: 0.9174 - val_loss: 0.9280 - val_accuracy: 0.9023 - lr: 1.0000e-04\n",
            "Epoch 117/300\n",
            "93/93 [==============================] - 3s 38ms/step - loss: 0.8770 - accuracy: 0.9227 - val_loss: 0.9159 - val_accuracy: 0.9085 - lr: 1.0000e-04\n",
            "Epoch 118/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.8940 - accuracy: 0.9162 - val_loss: 0.9028 - val_accuracy: 0.9054 - lr: 1.0000e-04\n",
            "Epoch 119/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.8614 - accuracy: 0.9173 - val_loss: 0.8913 - val_accuracy: 0.9098 - lr: 1.0000e-04\n",
            "Epoch 120/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.8493 - accuracy: 0.9239 - val_loss: 0.8865 - val_accuracy: 0.9078 - lr: 1.0000e-04\n",
            "Epoch 121/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.8536 - accuracy: 0.9210 - val_loss: 0.8849 - val_accuracy: 0.9078 - lr: 1.0000e-04\n",
            "Epoch 122/300\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.8526 - accuracy: 0.9213 - val_loss: 0.8745 - val_accuracy: 0.9040 - lr: 1.0000e-04\n",
            "Epoch 123/300\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.8407 - accuracy: 0.9188 - val_loss: 0.8728 - val_accuracy: 0.9078 - lr: 1.0000e-04\n",
            "Epoch 124/300\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.8110 - accuracy: 0.9256 - val_loss: 0.8605 - val_accuracy: 0.9102 - lr: 1.0000e-04\n",
            "Epoch 125/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.8128 - accuracy: 0.9239 - val_loss: 0.8497 - val_accuracy: 0.9123 - lr: 1.0000e-04\n",
            "Epoch 126/300\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.8057 - accuracy: 0.9264 - val_loss: 0.8398 - val_accuracy: 0.9143 - lr: 1.0000e-04\n",
            "Epoch 127/300\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.7997 - accuracy: 0.9242 - val_loss: 0.8419 - val_accuracy: 0.9095 - lr: 1.0000e-04\n",
            "Epoch 128/300\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.7947 - accuracy: 0.9227 - val_loss: 0.8224 - val_accuracy: 0.9133 - lr: 1.0000e-04\n",
            "Epoch 129/300\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.7669 - accuracy: 0.9325 - val_loss: 0.8256 - val_accuracy: 0.9140 - lr: 1.0000e-04\n",
            "Epoch 130/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.7817 - accuracy: 0.9257 - val_loss: 0.8110 - val_accuracy: 0.9126 - lr: 1.0000e-04\n",
            "Epoch 131/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.7636 - accuracy: 0.9310 - val_loss: 0.8019 - val_accuracy: 0.9181 - lr: 1.0000e-04\n",
            "Epoch 132/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.7624 - accuracy: 0.9305 - val_loss: 0.8037 - val_accuracy: 0.9112 - lr: 1.0000e-04\n",
            "Epoch 133/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.7515 - accuracy: 0.9312 - val_loss: 0.7926 - val_accuracy: 0.9153 - lr: 1.0000e-04\n",
            "Epoch 134/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.7578 - accuracy: 0.9298 - val_loss: 0.7947 - val_accuracy: 0.9140 - lr: 1.0000e-04\n",
            "Epoch 135/300\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.7316 - accuracy: 0.9323 - val_loss: 0.7851 - val_accuracy: 0.9143 - lr: 1.0000e-04\n",
            "Epoch 136/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.7281 - accuracy: 0.9342 - val_loss: 0.7810 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 137/300\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.7273 - accuracy: 0.9339 - val_loss: 0.7781 - val_accuracy: 0.9160 - lr: 1.0000e-04\n",
            "Epoch 138/300\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.7117 - accuracy: 0.9334 - val_loss: 0.7709 - val_accuracy: 0.9174 - lr: 1.0000e-04\n",
            "Epoch 139/300\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.7101 - accuracy: 0.9383 - val_loss: 0.7686 - val_accuracy: 0.9150 - lr: 1.0000e-04\n",
            "Epoch 140/300\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.6984 - accuracy: 0.9415 - val_loss: 0.7598 - val_accuracy: 0.9188 - lr: 1.0000e-04\n",
            "Epoch 141/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.6932 - accuracy: 0.9393 - val_loss: 0.7583 - val_accuracy: 0.9171 - lr: 1.0000e-04\n",
            "Epoch 142/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6907 - accuracy: 0.9376 - val_loss: 0.7516 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 143/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.6828 - accuracy: 0.9376 - val_loss: 0.7365 - val_accuracy: 0.9181 - lr: 1.0000e-04\n",
            "Epoch 144/300\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.6650 - accuracy: 0.9439 - val_loss: 0.7394 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 145/300\n",
            "93/93 [==============================] - 4s 46ms/step - loss: 0.6698 - accuracy: 0.9403 - val_loss: 0.7334 - val_accuracy: 0.9191 - lr: 1.0000e-04\n",
            "Epoch 146/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.6590 - accuracy: 0.9398 - val_loss: 0.7408 - val_accuracy: 0.9140 - lr: 1.0000e-04\n",
            "Epoch 147/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6450 - accuracy: 0.9452 - val_loss: 0.7375 - val_accuracy: 0.9147 - lr: 1.0000e-04\n",
            "Epoch 148/300\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.6484 - accuracy: 0.9446 - val_loss: 0.7243 - val_accuracy: 0.9157 - lr: 1.0000e-04\n",
            "Epoch 149/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.6611 - accuracy: 0.9395 - val_loss: 0.7334 - val_accuracy: 0.9157 - lr: 1.0000e-04\n",
            "Epoch 150/300\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.6284 - accuracy: 0.9410 - val_loss: 0.7277 - val_accuracy: 0.9133 - lr: 1.0000e-04\n",
            "Epoch 151/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.6386 - accuracy: 0.9422 - val_loss: 0.7295 - val_accuracy: 0.9109 - lr: 1.0000e-04\n",
            "Epoch 152/300\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6230 - accuracy: 0.9461 - val_loss: 0.7171 - val_accuracy: 0.9181 - lr: 1.0000e-04\n",
            "Epoch 153/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.6186 - accuracy: 0.9483 - val_loss: 0.6944 - val_accuracy: 0.9191 - lr: 1.0000e-04\n",
            "Epoch 154/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.6196 - accuracy: 0.9463 - val_loss: 0.6887 - val_accuracy: 0.9209 - lr: 1.0000e-04\n",
            "Epoch 155/300\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6275 - accuracy: 0.9383 - val_loss: 0.7012 - val_accuracy: 0.9174 - lr: 1.0000e-04\n",
            "Epoch 156/300\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.6026 - accuracy: 0.9478 - val_loss: 0.6991 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 157/300\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.6039 - accuracy: 0.9461 - val_loss: 0.6804 - val_accuracy: 0.9198 - lr: 1.0000e-04\n",
            "Epoch 158/300\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.5999 - accuracy: 0.9463 - val_loss: 0.6828 - val_accuracy: 0.9191 - lr: 1.0000e-04\n",
            "Epoch 159/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.5907 - accuracy: 0.9490 - val_loss: 0.6819 - val_accuracy: 0.9188 - lr: 1.0000e-04\n",
            "Epoch 160/300\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.5974 - accuracy: 0.9449 - val_loss: 0.6657 - val_accuracy: 0.9209 - lr: 1.0000e-04\n",
            "Epoch 161/300\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.5867 - accuracy: 0.9495 - val_loss: 0.6677 - val_accuracy: 0.9184 - lr: 1.0000e-04\n",
            "Epoch 162/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.5710 - accuracy: 0.9541 - val_loss: 0.6637 - val_accuracy: 0.9184 - lr: 1.0000e-04\n",
            "Epoch 163/300\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.5726 - accuracy: 0.9498 - val_loss: 0.6479 - val_accuracy: 0.9264 - lr: 1.0000e-04\n",
            "Epoch 164/300\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.5664 - accuracy: 0.9500 - val_loss: 0.6429 - val_accuracy: 0.9301 - lr: 1.0000e-04\n",
            "Epoch 165/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5649 - accuracy: 0.9517 - val_loss: 0.6440 - val_accuracy: 0.9229 - lr: 1.0000e-04\n",
            "Epoch 166/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.5616 - accuracy: 0.9498 - val_loss: 0.6624 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
            "Epoch 167/300\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.5617 - accuracy: 0.9515 - val_loss: 0.6482 - val_accuracy: 0.9212 - lr: 1.0000e-04\n",
            "Epoch 168/300\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.5545 - accuracy: 0.9498 - val_loss: 0.6348 - val_accuracy: 0.9253 - lr: 1.0000e-04\n",
            "Epoch 169/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.5405 - accuracy: 0.9535 - val_loss: 0.6459 - val_accuracy: 0.9250 - lr: 1.0000e-04\n",
            "Epoch 170/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.5410 - accuracy: 0.9512 - val_loss: 0.6333 - val_accuracy: 0.9274 - lr: 1.0000e-04\n",
            "Epoch 171/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.5382 - accuracy: 0.9534 - val_loss: 0.6409 - val_accuracy: 0.9260 - lr: 1.0000e-04\n",
            "Epoch 172/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5279 - accuracy: 0.9556 - val_loss: 0.6190 - val_accuracy: 0.9284 - lr: 1.0000e-04\n",
            "Epoch 173/300\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.5291 - accuracy: 0.9544 - val_loss: 0.6238 - val_accuracy: 0.9274 - lr: 1.0000e-04\n",
            "Epoch 174/300\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.5353 - accuracy: 0.9529 - val_loss: 0.6268 - val_accuracy: 0.9243 - lr: 1.0000e-04\n",
            "Epoch 175/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.5172 - accuracy: 0.9551 - val_loss: 0.6306 - val_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 176/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5192 - accuracy: 0.9525 - val_loss: 0.6311 - val_accuracy: 0.9264 - lr: 1.0000e-04\n",
            "Epoch 177/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.5174 - accuracy: 0.9556 - val_loss: 0.6200 - val_accuracy: 0.9270 - lr: 1.0000e-04\n",
            "Epoch 178/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.4976 - accuracy: 0.9635 - val_loss: 0.6077 - val_accuracy: 0.9274 - lr: 5.0000e-05\n",
            "Epoch 179/300\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4910 - accuracy: 0.9637 - val_loss: 0.6047 - val_accuracy: 0.9277 - lr: 5.0000e-05\n",
            "Epoch 180/300\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.4829 - accuracy: 0.9652 - val_loss: 0.6038 - val_accuracy: 0.9288 - lr: 5.0000e-05\n",
            "Epoch 181/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4782 - accuracy: 0.9658 - val_loss: 0.6023 - val_accuracy: 0.9288 - lr: 5.0000e-05\n",
            "Epoch 182/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4776 - accuracy: 0.9659 - val_loss: 0.6057 - val_accuracy: 0.9308 - lr: 5.0000e-05\n",
            "Epoch 183/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4818 - accuracy: 0.9634 - val_loss: 0.6095 - val_accuracy: 0.9295 - lr: 5.0000e-05\n",
            "Epoch 184/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4735 - accuracy: 0.9656 - val_loss: 0.6079 - val_accuracy: 0.9284 - lr: 5.0000e-05\n",
            "Epoch 185/300\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.4705 - accuracy: 0.9668 - val_loss: 0.5973 - val_accuracy: 0.9291 - lr: 5.0000e-05\n",
            "Epoch 186/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.4704 - accuracy: 0.9663 - val_loss: 0.5937 - val_accuracy: 0.9319 - lr: 5.0000e-05\n",
            "Epoch 187/300\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4557 - accuracy: 0.9691 - val_loss: 0.5982 - val_accuracy: 0.9322 - lr: 5.0000e-05\n",
            "Epoch 188/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4571 - accuracy: 0.9710 - val_loss: 0.6073 - val_accuracy: 0.9281 - lr: 5.0000e-05\n",
            "Epoch 189/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.4606 - accuracy: 0.9688 - val_loss: 0.5979 - val_accuracy: 0.9319 - lr: 5.0000e-05\n",
            "Epoch 190/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.4500 - accuracy: 0.9693 - val_loss: 0.5997 - val_accuracy: 0.9277 - lr: 5.0000e-05\n",
            "Epoch 191/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.4511 - accuracy: 0.9683 - val_loss: 0.5899 - val_accuracy: 0.9350 - lr: 5.0000e-05\n",
            "Epoch 192/300\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.4484 - accuracy: 0.9678 - val_loss: 0.5802 - val_accuracy: 0.9374 - lr: 5.0000e-05\n",
            "Epoch 193/300\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.4465 - accuracy: 0.9707 - val_loss: 0.5861 - val_accuracy: 0.9374 - lr: 5.0000e-05\n",
            "Epoch 194/300\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4474 - accuracy: 0.9708 - val_loss: 0.5779 - val_accuracy: 0.9357 - lr: 5.0000e-05\n",
            "Epoch 195/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.4376 - accuracy: 0.9703 - val_loss: 0.5878 - val_accuracy: 0.9326 - lr: 5.0000e-05\n",
            "Epoch 196/300\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.4368 - accuracy: 0.9713 - val_loss: 0.5820 - val_accuracy: 0.9357 - lr: 5.0000e-05\n",
            "Epoch 197/300\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.4330 - accuracy: 0.9736 - val_loss: 0.5859 - val_accuracy: 0.9343 - lr: 5.0000e-05\n",
            "Epoch 198/300\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.4357 - accuracy: 0.9700 - val_loss: 0.5693 - val_accuracy: 0.9350 - lr: 5.0000e-05\n",
            "Epoch 199/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.4358 - accuracy: 0.9702 - val_loss: 0.5776 - val_accuracy: 0.9326 - lr: 5.0000e-05\n",
            "Epoch 200/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.4312 - accuracy: 0.9712 - val_loss: 0.5741 - val_accuracy: 0.9332 - lr: 5.0000e-05\n",
            "Epoch 201/300\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4273 - accuracy: 0.9713 - val_loss: 0.5745 - val_accuracy: 0.9336 - lr: 5.0000e-05\n",
            "Epoch 202/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.4259 - accuracy: 0.9717 - val_loss: 0.5807 - val_accuracy: 0.9315 - lr: 5.0000e-05\n",
            "Epoch 203/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4354 - accuracy: 0.9674 - val_loss: 0.5639 - val_accuracy: 0.9353 - lr: 5.0000e-05\n",
            "Epoch 204/300\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.4153 - accuracy: 0.9759 - val_loss: 0.5753 - val_accuracy: 0.9329 - lr: 5.0000e-05\n",
            "Epoch 205/300\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.4167 - accuracy: 0.9730 - val_loss: 0.5765 - val_accuracy: 0.9329 - lr: 5.0000e-05\n",
            "Epoch 206/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.4206 - accuracy: 0.9717 - val_loss: 0.5772 - val_accuracy: 0.9315 - lr: 5.0000e-05\n",
            "Epoch 207/300\n",
            "93/93 [==============================] - 2s 23ms/step - loss: 0.4069 - accuracy: 0.9761 - val_loss: 0.5648 - val_accuracy: 0.9326 - lr: 5.0000e-05\n",
            "Epoch 208/300\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.4174 - accuracy: 0.9717 - val_loss: 0.5621 - val_accuracy: 0.9360 - lr: 5.0000e-05\n",
            "Epoch 209/300\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4076 - accuracy: 0.9752 - val_loss: 0.5580 - val_accuracy: 0.9326 - lr: 5.0000e-05\n",
            "Epoch 210/300\n",
            "93/93 [==============================] - 4s 37ms/step - loss: 0.4134 - accuracy: 0.9710 - val_loss: 0.5462 - val_accuracy: 0.9377 - lr: 5.0000e-05\n",
            "Epoch 211/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.4002 - accuracy: 0.9763 - val_loss: 0.5511 - val_accuracy: 0.9381 - lr: 5.0000e-05\n",
            "Epoch 212/300\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.4007 - accuracy: 0.9768 - val_loss: 0.5677 - val_accuracy: 0.9367 - lr: 5.0000e-05\n",
            "Epoch 213/300\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.4007 - accuracy: 0.9758 - val_loss: 0.5487 - val_accuracy: 0.9387 - lr: 5.0000e-05\n",
            "Epoch 214/300\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.4067 - accuracy: 0.9730 - val_loss: 0.5590 - val_accuracy: 0.9343 - lr: 5.0000e-05\n",
            "Epoch 215/300\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.3969 - accuracy: 0.9761 - val_loss: 0.5587 - val_accuracy: 0.9374 - lr: 5.0000e-05\n",
            "Epoch 216/300\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3915 - accuracy: 0.9771 - val_loss: 0.5565 - val_accuracy: 0.9350 - lr: 2.5000e-05\n",
            "Epoch 217/300\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3896 - accuracy: 0.9774 - val_loss: 0.5550 - val_accuracy: 0.9370 - lr: 2.5000e-05\n",
            "Epoch 218/300\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3865 - accuracy: 0.9781 - val_loss: 0.5518 - val_accuracy: 0.9377 - lr: 2.5000e-05\n",
            "Epoch 219/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3846 - accuracy: 0.9776 - val_loss: 0.5509 - val_accuracy: 0.9329 - lr: 2.5000e-05\n",
            "Epoch 220/300\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3810 - accuracy: 0.9800 - val_loss: 0.5535 - val_accuracy: 0.9350 - lr: 2.5000e-05\n",
            "Epoch 221/300\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3799 - accuracy: 0.9791 - val_loss: 0.5500 - val_accuracy: 0.9384 - lr: 1.2500e-05\n",
            "Epoch 222/300\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3730 - accuracy: 0.9819 - val_loss: 0.5489 - val_accuracy: 0.9387 - lr: 1.2500e-05\n",
            "Epoch 223/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.3818 - accuracy: 0.9788 - val_loss: 0.5510 - val_accuracy: 0.9381 - lr: 1.2500e-05\n",
            "Epoch 224/300\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.3705 - accuracy: 0.9819 - val_loss: 0.5506 - val_accuracy: 0.9363 - lr: 1.2500e-05\n",
            "Epoch 225/300\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.3740 - accuracy: 0.9802 - val_loss: 0.5499 - val_accuracy: 0.9363 - lr: 1.2500e-05\n",
            "91/91 [==============================] - 1s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.95       342\n",
            "           1       0.94      1.00      0.97       360\n",
            "           2       0.94      0.90      0.92       351\n",
            "           3       0.92      0.90      0.91       413\n",
            "           4       0.94      0.96      0.95       413\n",
            "           5       0.91      0.94      0.92       387\n",
            "           6       0.96      0.93      0.94       320\n",
            "           7       0.95      0.94      0.95       320\n",
            "\n",
            "    accuracy                           0.94      2906\n",
            "   macro avg       0.94      0.94      0.94      2906\n",
            "weighted avg       0.94      0.94      0.94      2906\n",
            "\n",
            "[[322  11   1   5   0   1   1   1]\n",
            " [  0 360   0   0   0   0   0   0]\n",
            " [  0   3 315   2  10  12   2   7]\n",
            " [ 14   6   5 370   1  15   0   2]\n",
            " [  0   2   2   3 396   2   6   2]\n",
            " [  0   0   3  16   5 362   0   1]\n",
            " [  1   0   3   4   8   4 298   2]\n",
            " [  1   0   5   2   2   3   5 302]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved trained model at /content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/model/Emotion_Voice_Detection_Model.h5 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the emotion from example audio files using trained model.\n",
        "!pip install librosa tensorflow\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configuration paths\n",
        "EXAMPLES_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/examples'\n",
        "MODEL_DIR_PATH = '/content/drive/MyDrive/NN Research/emotion-classification-from-audio-files-master/emotion-classification-from-audio-files-master/model'\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class LivePredictions:\n",
        "    \"\"\"\n",
        "    Main class of the application.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file):\n",
        "        \"\"\"\n",
        "        Init method is used to initialize the main parameters.\n",
        "        \"\"\"\n",
        "        self.file = file\n",
        "        self.path = os.path.join(MODEL_DIR_PATH, 'Emotion_Voice_Detection_Model.h5')\n",
        "\n",
        "        if not os.path.exists(self.path):\n",
        "            raise FileNotFoundError(f\"Model file not found: {self.path}\")\n",
        "\n",
        "        self.loaded_model = tf.keras.models.load_model(self.path)\n",
        "\n",
        "    def make_predictions(self):\n",
        "        \"\"\"\n",
        "        Method to process the files and create your features.\n",
        "        \"\"\"\n",
        "        data, sampling_rate = librosa.load(self.file, res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
        "        x = np.expand_dims(mfccs, axis=0)  # Add batch dimension\n",
        "        x = np.expand_dims(x, axis=2)  # Add channel dimension\n",
        "\n",
        "        predictions = self.loaded_model.predict(x)\n",
        "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "        print(f\"Prediction is: {self.convert_class_to_emotion(predicted_class)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_class_to_emotion(pred):\n",
        "        \"\"\"\n",
        "        Method to convert the predictions (int) into human readable strings.\n",
        "        \"\"\"\n",
        "        label_conversion = {\n",
        "            0: 'neutral',\n",
        "            1: 'calm',\n",
        "            2: 'happy',\n",
        "            3: 'sad',\n",
        "            4: 'angry',\n",
        "            5: 'fearful',\n",
        "            6: 'disgust',\n",
        "            7: 'surprised'\n",
        "        }\n",
        "\n",
        "        return label_conversion.get(pred, \"Unknown\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    example_file_1 = os.path.join(EXAMPLES_PATH, '03-02-02-02-01-02-05.wav')\n",
        "    example_file_2 = os.path.join(EXAMPLES_PATH, '03-02-05-02-02-01-01.wav')\n",
        "    example_file_3 = os.path.join(EXAMPLES_PATH, 'Happy.wav')\n",
        "\n",
        "    live_prediction = LivePredictions(file=example_file_1)\n",
        "    live_prediction.loaded_model.summary()\n",
        "    live_prediction.make_predictions()\n",
        "\n",
        "    live_prediction = LivePredictions(file=example_file_2)\n",
        "    live_prediction.make_predictions()\n",
        "\n",
        "    live_prediction = LivePredictions(file=example_file_3)\n",
        "    live_prediction.make_predictions()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5xgmL1Me9Wo",
        "outputId": "d7985eab-f860-48b5-cf08-7759807e567c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 40, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 40, 64)               256       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 40, 64)               256       ['conv1d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 40, 64)               0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 20, 64)               0         ['activation[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 20, 64)               0         ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 20, 128)              24704     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 20, 128)              512       ['conv1d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 20, 128)              0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 20, 128)              24704     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 20, 128)              49280     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 20, 128)              512       ['conv1d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 20, 128)              512       ['conv1d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 20, 128)              0         ['batch_normalization_3[0][0]'\n",
            "                                                                    , 'batch_normalization_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 20, 128)              0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPoolin  (None, 10, 128)              0         ['activation_2[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 10, 128)              0         ['max_pooling1d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 10, 256)              98560     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 10, 256)              1024      ['conv1d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 10, 256)              0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 10, 256)              98560     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 10, 256)              196864    ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 10, 256)              1024      ['conv1d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 10, 256)              1024      ['conv1d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 10, 256)              0         ['batch_normalization_6[0][0]'\n",
            "                                                                    , 'batch_normalization_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 10, 256)              0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPoolin  (None, 5, 256)               0         ['activation_4[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 5, 256)               0         ['max_pooling1d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 5, 512)               393728    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 5, 512)               2048      ['conv1d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 5, 512)               0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)           (None, 5, 512)               393728    ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)           (None, 5, 512)               786944    ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 5, 512)               2048      ['conv1d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 5, 512)               2048      ['conv1d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 5, 512)               0         ['batch_normalization_9[0][0]'\n",
            "                                                                    , 'batch_normalization_8[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 5, 512)               0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPoolin  (None, 2, 512)               0         ['activation_6[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 2, 512)               0         ['max_pooling1d_3[0][0]']     \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 512)                  0         ['dropout_3[0][0]']           \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 512)                  262656    ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 512)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 256)                  131328    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 256)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 8)                    2056      ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2474376 (9.44 MB)\n",
            "Trainable params: 2468872 (9.42 MB)\n",
            "Non-trainable params: 5504 (21.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 1s 869ms/step\n",
            "Prediction is: sad\n",
            "1/1 [==============================] - 0s 484ms/step\n",
            "Prediction is: sad\n",
            "1/1 [==============================] - 0s 353ms/step\n",
            "Prediction is: sad\n"
          ]
        }
      ]
    }
  ]
}